{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summariser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the age of internet and social network, We come across thousands of articles, blog-posts on daily basis. However, nobody has the time to go through entire information. To overcome this problem, we decided to develop an conventional A.I algorithm able to efficiently summarising large chunk of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Heap of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stem_word = [\"the\",\"a\",\"an\",\"was\",\"is\",\"are\",\"of\",\"etc..\",\"his\",\"her\",\"himself\",\"herself\",\"it\",\"for\",\"them\",\"they\",\"this\",\"that\",\"and\",\"with\"]\n",
    "weight={}\n",
    "max_heap=[tuple()]\n",
    "heap_size = 0\n",
    "def insert(weight_set):\n",
    "    max_heap.append(weight_set)\n",
    "    swim()\n",
    "def swim():\n",
    "    index = len(max_heap)-1\n",
    "    while (index > 1 and max_heap[(index)//2][0]< max_heap[index][0]):\n",
    "        swap((index)//2,index)\n",
    "        index = (index)//2\n",
    "    return\n",
    "def sink(n):\n",
    "    right_index = 2*n+1\n",
    "    left_index = 2*n\n",
    "    source = n\n",
    "    if (right_index<(len(max_heap)-1) and max_heap[right_index][0]>max_heap[source][0]):\n",
    "        source = right_index\n",
    "    if (right_index<(len(max_heap)-1) and max_heap[left_index][0]>max_heap[source][0]):\n",
    "        source = left_index\n",
    "    if (source != n):\n",
    "        swap(n,source)\n",
    "        sink(source)\n",
    "    return\n",
    "def swap(a,b):\n",
    "    max_heap[a],max_heap[b]=max_heap[b],max_heap[a]\n",
    "def pop():\n",
    "    index = len(max_heap)-1\n",
    "    val = max_heap[1]\n",
    "    max_heap[1] = max_heap[index]\n",
    "    del max_heap[index]\n",
    "    sink(1)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Min heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "min_heap=[tuple()]\n",
    "def insert1(weight_set):\n",
    "    min_heap.append(weight_set)\n",
    "    swim1()\n",
    "def swim1():\n",
    "    index = len(min_heap)-1\n",
    "    while (index > 1 and min_heap[(index)//2][0]> min_heap[index][0]):\n",
    "        swap1((index)//2,index)\n",
    "        index = (index)//2\n",
    "    return\n",
    "def sink1(n):\n",
    "    right_index = 2*n+1\n",
    "    left_index = 2*n\n",
    "    source = n\n",
    "    if (right_index<(len(min_heap)-1) and min_heap[right_index][0]<min_heap[source][0]):\n",
    "        source = right_index\n",
    "    if (right_index<(len(min_heap)-1) and min_heap[left_index][0]<min_heap[source][0]):\n",
    "        source = left_index\n",
    "    if (source != n):\n",
    "        swap1(n,source)\n",
    "        sink1(source)\n",
    "    return\n",
    "def swap1(a,b):\n",
    "    min_heap[a],min_heap[b]=min_heap[b],min_heap[a]\n",
    "def pop1():\n",
    "    index = len(min_heap)-1\n",
    "    val = min_heap[1]\n",
    "    min_heap[1] = min_heap[index]\n",
    "    del min_heap[index]\n",
    "    sink1(1)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    file1=open(\"textpara.txt\",\"r+\");\n",
    "    text_string = file1.read().lower()\n",
    "    match_pattern = re.findall(r'\\b[a-z]{3,25}\\b', text_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generating word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impetus of the algorithm is in the generation of word vector for every sentence. Weights are calulcated by adding the number of appearances of the word in the document. After calculating appearance for each word, it is divided by the total number of word in the document to get normalised weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing 0.006134969325153374\n",
      "them 0.012269938650306749\n",
      "their 0.006134969325153374\n",
      "vast 0.006134969325153374\n",
      "truth 0.006134969325153374\n",
      "non 0.012269938650306749\n",
      "laugh 0.006134969325153374\n",
      "critters 0.006134969325153374\n",
      "turning 0.006134969325153374\n",
      "into 0.006134969325153374\n",
      "common 0.006134969325153374\n",
      "add 0.006134969325153374\n",
      "moral 0.006134969325153374\n",
      "birds 0.006134969325153374\n",
      "human 0.018404907975460124\n",
      "including 0.006134969325153374\n",
      "funny 0.006134969325153374\n",
      "death 0.006134969325153374\n",
      "will 0.006134969325153374\n",
      "societal 0.006134969325153374\n",
      "all 0.012269938650306749\n",
      "lion 0.006134969325153374\n",
      "humorous 0.006134969325153374\n",
      "globe 0.006134969325153374\n",
      "soul 0.006134969325153374\n",
      "contains 0.006134969325153374\n",
      "read 0.006134969325153374\n",
      "old 0.006134969325153374\n",
      "principles 0.006134969325153374\n",
      "delve 0.006134969325153374\n",
      "your 0.012269938650306749\n",
      "tales 0.018404907975460124\n",
      "people 0.012269938650306749\n",
      "not 0.006134969325153374\n",
      "popular 0.006134969325153374\n",
      "short 0.006134969325153374\n",
      "treasure 0.006134969325153374\n",
      "etc 0.012269938650306749\n",
      "but 0.006134969325153374\n",
      "this 0.006134969325153374\n",
      "god 0.006134969325153374\n",
      "rabbit 0.006134969325153374\n",
      "elephant 0.006134969325153374\n",
      "sad 0.006134969325153374\n",
      "welcome 0.006134969325153374\n",
      "yours 0.006134969325153374\n",
      "would 0.012269938650306749\n",
      "dog 0.006134969325153374\n",
      "fish 0.006134969325153374\n",
      "forget 0.006134969325153374\n",
      "with 0.006134969325153374\n",
      "some 0.018404907975460124\n",
      "for 0.012269938650306749\n",
      "righteousness 0.006134969325153374\n",
      "that 0.018404907975460124\n",
      "they 0.006134969325153374\n",
      "friends 0.006134969325153374\n",
      "are 0.03680981595092025\n",
      "relationships 0.006134969325153374\n",
      "from 0.006134969325153374\n",
      "unity 0.006134969325153374\n",
      "around 0.006134969325153374\n",
      "love 0.006134969325153374\n",
      "respect 0.006134969325153374\n",
      "ever 0.006134969325153374\n",
      "divinity 0.006134969325153374\n",
      "animal 0.024539877300613498\n",
      "time 0.006134969325153374\n",
      "brer 0.006134969325153374\n",
      "tiger 0.006134969325153374\n",
      "values 0.006134969325153374\n",
      "such 0.006134969325153374\n",
      "more 0.006134969325153374\n",
      "crazy 0.006134969325153374\n",
      "cats 0.006134969325153374\n",
      "other 0.006134969325153374\n",
      "reading 0.006134969325153374\n",
      "there 0.006134969325153374\n",
      "grow 0.006134969325153374\n",
      "humans 0.006134969325153374\n",
      "underlining 0.006134969325153374\n",
      "fortnight 0.006134969325153374\n",
      "heart 0.006134969325153374\n",
      "every 0.006134969325153374\n",
      "you 0.012269938650306749\n",
      "have 0.012269938650306749\n",
      "because 0.006134969325153374\n",
      "these 0.03067484662576687\n",
      "which 0.006134969325153374\n",
      "rectitude 0.006134969325153374\n",
      "trove 0.006134969325153374\n",
      "and 0.049079754601226995\n",
      "dogs 0.006134969325153374\n",
      "one 0.006134969325153374\n",
      "touch 0.006134969325153374\n",
      "about 0.018404907975460124\n",
      "stories 0.05521472392638037\n",
      "others 0.006134969325153374\n",
      "page 0.006134969325153374\n",
      "priority 0.006134969325153374\n",
      "the 0.04294478527607362\n",
      "both 0.006134969325153374\n",
      "impart 0.006134969325153374\n",
      "tell 0.006134969325153374\n",
      "enjoy 0.012269938650306749\n",
      "sampling 0.006134969325153374\n",
      "mutual 0.006134969325153374\n",
      "passes 0.006134969325153374\n",
      "share 0.006134969325153374\n"
     ]
    }
   ],
   "source": [
    "    for word in match_pattern:\n",
    "        count = weight.get(word,0)\n",
    "        weight[word] = count + 1\n",
    "    frequency_list = weight.keys()\n",
    "    for words in frequency_list:\n",
    "        print(words, weight[words]/sum(weight.values()))\n",
    "    file1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PART 2\n",
      "relationships.\n",
      "critters.\n",
      "both.\n",
      "animal.\n",
      "soul.\n",
      "stories.\n",
      "passes.\n",
      "fortnight.\n",
      "sampling.\n",
      "etc...\n",
      "values.\n",
      "them.\n"
     ]
    }
   ],
   "source": [
    "    print(\"\\n\\nPART 2\")\n",
    "    file1=open(\"textpara.txt\",\"r+\");\n",
    "    sentence = file1.read().lower().split()\n",
    "    for word in sentence:\n",
    "        if word[-1]==\".\":\n",
    "            print(word)\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(), (25728140, 'laugh at the humorous stories and enjoy the tales from around the globe and do not forget to delve into them.'), (1644762, 'there are tales about dog, tiger, lion, elephant, etc...'), (2277968, '- stories which have a moral and impart values.'), (432183, 'you are welcome to share these stories with your friends.these are stories that grow ever more popular as time passes.'), (670876, 'a vast treasure trove of animal tales is yours for the sampling.'), (71230, 'the underlining principles would be truth, love, mutual respect, righteousness, rectitude, divinity, priority to societal unity, etcâ€¦all people, including the old people, would enjoy reading these stories.'), (17381, 'but one thing that all of these stories have in common is that they will touch your heart and soul.'), (204, 'this page contains animal stories about their human and non-human animal relationships.'), (5592, 'others tell of humans turning to god because of the death of a non-human animal.'), (1835, 'some of them are sad, some are funny, and some are both.'), (485625, 'and we add such stories for you every fortnight.'), (1145, 'read these short stories about dogs, cats, brer rabbit, birds, fish, and other crazy critters.')]\n"
     ]
    }
   ],
   "source": [
    "    local_sentence= []\n",
    "    weight_sentence=0\n",
    "    for word in sentence:\n",
    "        if word[-1]==\".\":\n",
    "            if (word[0:-1] in stem_word):\n",
    "                pass\n",
    "            else:\n",
    "                weight_sentence+=weight[word[0:-1]]\n",
    "            local_sentence.append(word)\n",
    "            insert(tuple((weight_sentence,\" \".join(local_sentence))))\n",
    "            weight_sentence=0\n",
    "            local_sentence = []\n",
    "        else:\n",
    "            if (word in stem_word):\n",
    "                pass\n",
    "            else:\n",
    "                count+=weight.get(word,0)\n",
    "                weight_sentence+=count\n",
    "                weight[word]=count\n",
    "            local_sentence.append(word)\n",
    "    print(max_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    for _ in range(len(max_heap)//3):\n",
    "        insert1(pop())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A vast treasure trove of animal tales is yours for the sampling.  \n",
      "Laugh at the humorous stories and enjoy the tales from around the globe and do not forget to delve into them.  \n",
      "- stories which have a moral and impart values.  \n",
      "There are tales about dog, tiger, lion, elephant, etc...  \n"
     ]
    }
   ],
   "source": [
    "    for i in range(len(min_heap)-1):\n",
    "        print(pop1()[1].capitalize(),\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
